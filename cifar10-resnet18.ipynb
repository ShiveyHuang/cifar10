{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器选择标志，设置为 ''SGD_with_Momentum' 'SGD' 'Adam'' 'AdaGrad' 'RMSProp' 'Adadelta'通过修改这里来切换优化器及相关命名\n",
    "# optimizer_type = 'SGD_with_Momentum'  # 可以修改为 'SGD'\n",
    "\n",
    "# 训练总次数\n",
    "epochs = 100\n",
    "# 每次取出的样本数\n",
    "batch_size=128\n",
    "# 设置学习率集合\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "optimizer_types = ['SGD_with_Momentum', 'SGD', 'Adam', 'AdaGrad', 'RMSProp', 'Adadelta']\n",
    "# [(0.0001, 'SGD_with_Momentum'), (0.0001, 'SGD'), (0.0001, 'Adam'), (0.0001, 'AdaGrad'), (0.0001, 'RMSProp'), (0.0001, 'Adadelta'), (0.001, 'SGD_with_Momentum'), (0.001, 'SGD'), (0.001, 'Adam'), (0.001, 'AdaGrad'), (0.001, 'RMSProp'), (0.001, 'Adadelta'), (0.01, 'SGD_with_Momentum'), (0.01, 'SGD'), (0.01, 'Adam'), (0.01, 'AdaGrad'), (0.01, 'RMSProp'), (0.01, 'Adadelta')]\n",
    "lr_optims = [\n",
    "    (0.1, 'Adadelta'), # 特殊的学习率优化器组合\n",
    "]\n",
    "lr_optims += [(lr, optim) for lr in learning_rates for optim in optimizer_types] # 常规的学习率优化器组合\n",
    "\n",
    "# 学习调度器StepLR 相关参数\n",
    "# step_size = 50  # 每50个轮次降低一次学习率，可根据实验调整\n",
    "# gamma = 0.1  # 学习率衰减因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(3. / 4., 4. / 3.)),  # 随机裁剪到32x32\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # 颜色抖动\n",
    "    transforms.RandomGrayscale(p=0.1),  # 随机灰度化\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])  # 标准化\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(36),  # 调整大小以适应后续裁剪\n",
    "    transforms.CenterCrop(32),  # 居中裁剪为32x32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])  # 标准化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "train_dataset = datasets.CIFAR10(root='./dataset', train=True, transform=transform_train, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./dataset', train=False, transform=transform_test, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义残差块\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(Y + X)\n",
    "\n",
    "# 定义ResNet-18网络\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # 动态调整宽高\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            use_1x1conv = (self.in_channels!= out_channels or stride!= 1)\n",
    "            layers.append(block(self.in_channels, out_channels, use_1x1conv=use_1x1conv, stride=stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.bn1(self.conv1(X)))\n",
    "        X = self.layer1(X)\n",
    "        X = self.layer2(X)\n",
    "        X = self.layer3(X)\n",
    "        X = self.layer4(X)\n",
    "        X = self.global_avg_pool(X)  # 输出大小为 (batch_size, 512, 1, 1)\n",
    "        return self.linear(X.view(X.shape[0], -1))  # 展平成 (batch_size, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "def get_net(devices):\n",
    "    num_classes = 10\n",
    "    model = ResNet(Residual, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    if torch.cuda.is_available():\n",
    "        model = nn.DataParallel(model, device_ids=list(range(len(devices))))  # 使用所有 GPU\n",
    "        model.to(devices[0])  # 将模型移动到主 GPU 上\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 评估指标函数\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_accuracy(net, data_loader, device, lr):\n",
    "    net.eval()  # 切换到评估模式\n",
    "    correct, total = 0, 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # 绘制并保存混淆矩阵图片\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(range(10)), yticklabels=list(range(10)))\n",
    "    plt.title(f'Confusion Matrix (lr={lr})')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    file_name = f'result/{optimizer_type}-confusion-matrix-lr:{lr}.png'\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, precision, recall, f1, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# 创建保存文件的目录（如果不存在）\n",
    "if not os.path.exists('picture'):\n",
    "    os.makedirs('picture')\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "if not os.path.exists('record'):\n",
    "    os.makedirs('record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学习率: 0.0001, 训练轮数 1/100\n",
      "Epoch 1: Loss = 2.1185, Accuracy = 21.4880%\n",
      "学习率: 0.0001, 训练轮数 2/100\n",
      "Epoch 2: Loss = 1.8729, Accuracy = 30.7260%\n",
      "学习率: 0.0001, 训练轮数 3/100\n",
      "Epoch 3: Loss = 1.7541, Accuracy = 35.5180%\n",
      "学习率: 0.0001, 训练轮数 4/100\n",
      "Epoch 4: Loss = 1.6759, Accuracy = 38.4300%\n",
      "学习率: 0.0001, 训练轮数 5/100\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def particular_train(optimizer_type, lr):\n",
    "    # 实例化模型并移动到GPU（如果有）\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else [torch.device('cpu')]\n",
    "    net = get_net(devices)\n",
    "    \n",
    "    # 根据选择的优化器类型创建相应的优化器\n",
    "    if optimizer_type == 'SGD_with_Momentum':\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "    elif optimizer_type == 'SGD':\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0, weight_decay=0.0005)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.0005)\n",
    "    elif optimizer_type == 'AdaGrad':\n",
    "        optimizer = torch.optim.Adagrad(net.parameters(), lr=lr, weight_decay=0.0005)\n",
    "    elif optimizer_type == 'RMSProp':\n",
    "        optimizer = torch.optim.RMSprop(net.parameters(), lr=lr, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0)\n",
    "    elif optimizer_type == 'Adadelta':\n",
    "        optimizer = torch.optim.Adadelta(net.parameters(), lr=lr, rho=0.9, eps=1e-6, weight_decay=0.0005)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer type. Please choose 'SGD_with_Momentum', 'SGD', 'Adam', 'AdaGrad', 'RMSProp' or 'Adadelta'.\")\n",
    "    \n",
    "    # 创建StepLR学习率调度器\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)    \n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 100], gamma = 0.1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 50, eta_min = 0.001)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 50, T_mult = 2, eta_min = 0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    # 训练循环\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"学习率: {lr}, 训练轮数 {epoch + 1}/{epochs}\")\n",
    "        net.train()  # 切换到训练模式\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(devices[0]), labels.to(devices[0])  # 数据加载到主 GPU\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()  # 清空梯度\n",
    "            loss.backward()\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "            # 统计训练损失和准确率\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / total\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4%}\")\n",
    "        # 调用学习率调度器的step方法，更新学习率\n",
    "        # scheduler.step()\n",
    "        \n",
    "    # 保存当前学习率下的训练损失和准确率到CSV文件\n",
    "    data = {\n",
    "        '轮次': list(range(1, epochs + 1)),\n",
    "        '训练损失': train_losses,\n",
    "        '训练准确率': train_accuracies\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    file_name = f'record/{optimizer_type}-training-record-lr:{lr}.csv'\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "    # 绘制损失和准确率曲线\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss', color='r')  # 设置损失曲线颜色为红色\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    # 添加网格\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # 绘制准确率曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy', color='b')  # 设置准确率曲线颜色为蓝色\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    # 添加网格\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 根据是损失图还是准确率图来设置文件名\n",
    "    file_name_loss_acc = f'picture/{optimizer_type}-train-loss-accuracy-lr:{lr}.png'\n",
    "    # 保存损失和准确率曲线图片\n",
    "    plt.savefig(file_name_loss_acc)\n",
    "    plt.show()\n",
    "\n",
    "    # 测试阶段\n",
    "    net.eval()  # 切换到评估模式\n",
    "    accuracy, precision, recall, f1, conf_matrix = evaluate_accuracy(net, test_loader, devices[0],lr)\n",
    "    print(f\"测试准确率: {accuracy:.2%}\")\n",
    "    print(f\"测试精确率: {precision:.2%}\")\n",
    "    print(f\"测试召回率: {recall:.2%}\")\n",
    "    print(f\"测试F1值: {f1:.2%}\")\n",
    "    print(\"混淆矩阵:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # 将评估指标保存为CSV文件\n",
    "    data = {\n",
    "        '指标': ['准确率', '精确率', '召回率', 'F1值'],\n",
    "        '数值': [accuracy, precision, recall, f1]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    file_name = f'result/{optimizer_type}-test-metrics-lr:{lr}.csv'\n",
    "    df.to_csv(file_name, index=False)\n",
    "    # 保存模型\n",
    "    model_path = f'model/{optimizer_type}-ResNet-18-lr:{lr}.pth'\n",
    "    if isinstance(net, nn.DataParallel):\n",
    "        torch.save(net.module.state_dict(), model_path)\n",
    "    else:\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "\n",
    "# 遍历学习率优化器对\n",
    "for lr_optim in lr_optims:\n",
    "    lr, optim = lr_optim\n",
    "    particular_train(lr=lr, optimizer_type=optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
